{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10d895d6",
   "metadata": {},
   "source": [
    "# Create Fair Bingo Cards from Segmentation Stats\n",
    "\n",
    "This notebook implements a statistical approach to generating \"fair\" Bingo cards based on satellite image segmentation results.\n",
    "\n",
    "**The Goal:**\n",
    "Generate $N$ Bingo cards, each with 10 squares (conditions like \"Has a Pool\", \"More than 2 Cars\").\n",
    "The game is played by showing images in a random order.\n",
    "\"Fairness\" means every card should have approximately the same **Expected Time to Win** (number of images revealed until the card is full).\n",
    "\n",
    "**The Method:**\n",
    "1. **Load Stats**: Read `segmentation_stats.csv`.\n",
    "2. **Define Events**: Generate a universe of possible squares (Existence, >N, ==N).\n",
    "3. **Truth Matrix**: Pre-calculate which images satisfy which events.\n",
    "4. **Monte Carlo Simulation**: To measure the difficulty of a card, we simulate thousands of games (shuffling images) and calculate the average number of draws needed to complete the card.\n",
    "5. **Balancing**: We generate random cards and filter/reject those that are too easy or too hard, ensuring a tight distribution of difficulty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5a60f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# 1. Load Data\n",
    "# Resolve path relative to this notebook\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "CSV_PATH = PROJECT_ROOT / \"mask\" / \"segmentation_stats.csv\"\n",
    "\n",
    "if not CSV_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Stats file not found: {CSV_PATH}\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Fill NaNs in n_objects with 0 (missing feature = 0 count)\n",
    "df[\"n_objects\"] = df[\"n_objects\"].fillna(0).astype(int)\n",
    "\n",
    "print(f\"Loaded {len(df)} rows from {CSV_PATH}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d644f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Preprocess: Create Image-Feature Count Matrix\n",
    "# We want a matrix where index=Image, columns=Features, values=Count\n",
    "# This makes it easy to check conditions across all images at once.\n",
    "\n",
    "# Pivot the table\n",
    "counts_matrix = df.pivot_table(index=\"image\", columns=\"feature\", values=\"n_objects\", fill_value=0)\n",
    "\n",
    "# Ensure we have all images (some might have no features and be missing if not handled carefully, \n",
    "# but here the CSV comes from a process that lists features found. \n",
    "# If an image has NO features found, it might be missing from the CSV unless the script outputted 0-count rows.\n",
    "# Let's assume the CSV covers the relevant images.)\n",
    "\n",
    "print(f\"Matrix shape: {counts_matrix.shape} (Images x Features)\")\n",
    "display(counts_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985934ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f92ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Generate Candidate Bingo Squares (Events)\n",
    "\n",
    "def generate_events(matrix, feature_event_types=None):\n",
    "    events = []\n",
    "    \n",
    "    features = matrix.columns\n",
    "    n_images = len(matrix)\n",
    "    \n",
    "    for feat in features:\n",
    "        col = matrix[feat]\n",
    "        \n",
    "        # Determine which types to generate\n",
    "        if feature_event_types is not None:\n",
    "            selected_types = feature_event_types.get(feat, [])\n",
    "        else:\n",
    "            selected_types = ['exists', 'threshold', 'exact']  # All types if not specified\n",
    "        \n",
    "        # 1. Existence: \"Contains a [Feature]\"\n",
    "        # Condition: count > 0\n",
    "        if 'exists' in selected_types:\n",
    "            mask = col > 0\n",
    "            prob = mask.mean()\n",
    "            if 0.001 <= prob <= 0.95: # Filter trivial or impossible events\n",
    "                events.append({\n",
    "                    \"description\": f\"Contains {feat}\",\n",
    "                    \"type\": \"exists\",\n",
    "                    \"feature\": feat,\n",
    "                    \"condition\": lambda c: c > 0,\n",
    "                    \"mask\": mask.values,\n",
    "                    \"probability\": prob\n",
    "                })\n",
    "            \n",
    "        # 2. Thresholds: \"More than N [Feature]s\"\n",
    "        # Check reasonable thresholds based on data\n",
    "        max_val = col.max()\n",
    "        if 'threshold' in selected_types and max_val > 1:\n",
    "            for n in range(1, min(int(max_val), 6)): # Check 1..5\n",
    "                mask = col > n\n",
    "                prob = mask.mean()\n",
    "                if 0.05 <= prob <= 0.95:\n",
    "                    events.append({\n",
    "                        \"description\": f\"More than {n} {feat}s\",\n",
    "                        \"type\": \"threshold\",\n",
    "                        \"feature\": feat,\n",
    "                        \"condition\": lambda c, n=n: c > n, # capture n\n",
    "                        \"mask\": mask.values,\n",
    "                        \"probability\": prob\n",
    "                    })\n",
    "\n",
    "        # 3. Exact Counts: \"Exactly N [Feature]s\"\n",
    "        # Useful for small numbers\n",
    "        if 'exact' in selected_types and max_val >= 1:\n",
    "            for n in range(1, min(int(max_val) + 1, 6)):\n",
    "                mask = col == n\n",
    "                prob = mask.mean()\n",
    "                if 0.05 <= prob <= 0.95:\n",
    "                    events.append({\n",
    "                        \"description\": f\"Exactly {n} {feat}{'s' if n>1 else ''}\",\n",
    "                        \"type\": \"exact\",\n",
    "                        \"feature\": feat,\n",
    "                        \"condition\": lambda c, n=n: c == n,\n",
    "                        \"mask\": mask.values,\n",
    "                        \"probability\": prob\n",
    "                    })\n",
    "                    \n",
    "    return pd.DataFrame(events)\n",
    "\n",
    "# Get unique features from the matrix\n",
    "features = list(counts_matrix.columns)\n",
    "\n",
    "# Create a widget for each feature\n",
    "feature_widgets = {}\n",
    "for feat in features:\n",
    "    # Checkboxes for event types\n",
    "    exists_cb = widgets.Checkbox(value=True, description='Contains')\n",
    "    threshold_cb = widgets.Checkbox(value=False, description='More than N')\n",
    "    exact_cb = widgets.Checkbox(value=False, description='Exactly N')\n",
    "    \n",
    "    # Group them in a VBox\n",
    "    box = widgets.VBox([widgets.Label(f\"Feature: {feat}\"), exists_cb, threshold_cb, exact_cb])\n",
    "    feature_widgets[feat] = box  # Store the VBox\n",
    "\n",
    "# Display all widgets\n",
    "widgets_list = [feature_widgets[feat] for feat in features]  # Use the VBox directly\n",
    "accordion = widgets.Accordion(children=widgets_list, titles=features)\n",
    "display(accordion)\n",
    "\n",
    "# Button to confirm selection\n",
    "confirm_button = widgets.Button(description=\"Confirm Selections\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_confirm_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        feature_event_types = {}\n",
    "        for feat, box in feature_widgets.items():\n",
    "            # box.children: [Label, exists_cb, threshold_cb, exact_cb]\n",
    "            exists_val = box.children[1].value\n",
    "            threshold_val = box.children[2].value\n",
    "            exact_val = box.children[3].value\n",
    "            selected = []\n",
    "            if exists_val:\n",
    "                selected.append('exists')\n",
    "            if threshold_val:\n",
    "                selected.append('threshold')\n",
    "            if exact_val:\n",
    "                selected.append('exact')\n",
    "            feature_event_types[feat] = selected\n",
    "        print(\"Selected event types per feature:\")\n",
    "        for feat, types in feature_event_types.items():\n",
    "            print(f\"{feat}: {types}\")\n",
    "        # Now generate events\n",
    "        global events_df\n",
    "        events_df = generate_events(counts_matrix, feature_event_types)\n",
    "        print(f\"Generated {len(events_df)} candidate events.\")\n",
    "        display(events_df[[\"description\", \"probability\"]].sort_values(\"probability\").head(10))\n",
    "        display(events_df[[\"description\", \"probability\"]].sort_values(\"probability\", ascending=False).head(10))\n",
    "\n",
    "confirm_button.on_click(on_confirm_clicked)\n",
    "display(confirm_button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f207afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Compute Truth Matrix\n",
    "# Rows = Images, Cols = Events\n",
    "# Value = True if Image satisfies Event\n",
    "# We already stored the masks in the events_df, let's stack them.\n",
    "\n",
    "truth_matrix = np.stack(events_df[\"mask\"].values).T # Shape: (n_images, n_events)\n",
    "print(f\"Truth Matrix Shape: {truth_matrix.shape}\")\n",
    "\n",
    "# Verify\n",
    "# truth_matrix[i, j] is True if Image i satisfies Event j\n",
    "\n",
    "print(truth_matrix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337f5b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Define Monte Carlo Simulation for Card Difficulty\n",
    "\n",
    "def calculate_turns_to_win(card_indices, truth_matrix, n_simulations=1000000):\n",
    "    \"\"\"\n",
    "    Simulates the game n_simulations times for a given card.\n",
    "    Returns the average number of turns (images drawn) to complete the card.\n",
    "    \"\"\"\n",
    "    n_images, n_events = truth_matrix.shape\n",
    "    card_mask = truth_matrix[:, card_indices] # Shape: (n_images, 10)\n",
    "    \n",
    "    # If a card has an event that is NEVER satisfied by any image, it's impossible.\n",
    "    # Check if any column in card_mask is all False\n",
    "    if np.any(card_mask.sum(axis=0) == 0):\n",
    "        return float('inf') # Impossible card\n",
    "    \n",
    "    turns_needed = []\n",
    "    \n",
    "    # Create an array of image indices [0, 1, ... N-1]\n",
    "    deck = np.arange(n_images)\n",
    "    \n",
    "    for _ in range(n_simulations):\n",
    "        np.random.shuffle(deck)\n",
    "        \n",
    "        # We want to find the first index k such that the union of images deck[0]...deck[k]\n",
    "        # covers all requirements.\n",
    "        \n",
    "        # Reorder the card_mask according to the shuffled deck\n",
    "        shuffled_mask = card_mask[deck] # Shape: (n_images, 10)\n",
    "        \n",
    "        # Cumulative sum (or rather, cumulative OR)\n",
    "        # We want to know when we have seen a True for every column.\n",
    "        # np.maximum.accumulate works like cumulative OR for booleans (0/1)\n",
    "        covered_cum = np.maximum.accumulate(shuffled_mask, axis=0) # Shape: (n_images, 10)\n",
    "        \n",
    "        # Check if all 10 are covered at each step\n",
    "        all_covered = covered_cum.all(axis=1) # Shape: (n_images,)\n",
    "        \n",
    "        # Find the first index where all_covered is True\n",
    "        # argmax returns the first True index. If none are True, it returns 0 (but we checked impossibility)\n",
    "        # We add 1 because turns are 1-based (1st image is index 0)\n",
    "        if not all_covered.any():\n",
    "             # Should not happen if we checked impossibility, unless n_images < needed?\n",
    "             # But we assume infinite deck or deck=all images. \n",
    "             # If deck=all images and it's possible, it will happen.\n",
    "             turns = n_images \n",
    "        else:\n",
    "            turns = np.argmax(all_covered) + 1\n",
    "            \n",
    "        turns_needed.append(turns)\n",
    "        \n",
    "    return np.mean(turns_needed)\n",
    "\n",
    "# Test with a random card\n",
    "random_card_indices = random.sample(range(len(events_df)), 10)\n",
    "avg_turns = calculate_turns_to_win(random_card_indices, truth_matrix)\n",
    "print(f\"Random Card Average Turns to Win: {avg_turns:.2f} (out of {len(counts_matrix)} images)\")\n",
    "print(\"Card Events:\")\n",
    "print(events_df.iloc[random_card_indices][\"description\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f88c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Generate and Filter Fair Bingo Cards\n",
    "\n",
    "NUM_CARDS = 50\n",
    "CARD_SIZE = 10\n",
    "TOLERANCE = 1 # Allowable deviation from target turns\n",
    "MANUAL_TARGET = 29 # Set to a number (e.g. 45) to force a specific difficulty, or None to auto-calculate\n",
    "\n",
    "# Pre-calculate feature groups for constrained sampling\n",
    "# We want exactly one event per feature to avoid \"Contains Pool\" AND \"More than 2 Pools\" on same card\n",
    "feature_groups = events_df.groupby(\"feature\").indices # dict: feature -> array of positional indices\n",
    "unique_features = list(feature_groups.keys())\n",
    "\n",
    "if len(unique_features) < CARD_SIZE:\n",
    "    raise ValueError(f\"Cannot create cards of size {CARD_SIZE}: Only {len(unique_features)} unique features available.\")\n",
    "\n",
    "# First, estimate a \"Target Difficulty\" by sampling random cards\n",
    "print(\"Estimating baseline difficulty...\")\n",
    "sample_difficulties = []\n",
    "for _ in range(50):\n",
    "    # Generate a random constrained card for baseline\n",
    "    feats = random.sample(unique_features, CARD_SIZE)\n",
    "    idxs = [random.choice(feature_groups[f]) for f in feats]\n",
    "    d = calculate_turns_to_win(idxs, truth_matrix, n_simulations=100)\n",
    "    if d != float('inf'):\n",
    "        sample_difficulties.append(d)\n",
    "\n",
    "if MANUAL_TARGET is not None:\n",
    "    target_difficulty = MANUAL_TARGET\n",
    "    print(f\"Using Manual Target Average Turns to Win: {target_difficulty:.2f}\")\n",
    "else:\n",
    "    target_difficulty = np.median(sample_difficulties)\n",
    "    print(f\"Calculated Target Average Turns to Win (Median): {target_difficulty:.2f}\")\n",
    "\n",
    "final_cards = []\n",
    "final_stats = []\n",
    "\n",
    "print(f\"Generating {NUM_CARDS} fair cards...\")\n",
    "pbar = tqdm(total=NUM_CARDS)\n",
    "\n",
    "attempts = 0\n",
    "MAX_ATTEMPTS = NUM_CARDS * 5000 # Safety break\n",
    "\n",
    "while len(final_cards) < NUM_CARDS:\n",
    "    attempts += 1\n",
    "    \n",
    "    # 1. Pick N unique features (The \"Combination\")\n",
    "    # We stick with this set of features and try to find a working configuration of events\n",
    "    selected_features = random.sample(unique_features, CARD_SIZE)\n",
    "    \n",
    "    # 2. Try to find a valid configuration for these features\n",
    "    # We'll try multiple times to find a valid set of conditions (events) for these specific features\n",
    "    # before giving up and picking a new set of features.\n",
    "    # This helps if a feature set is \"good\" but we just picked the wrong difficulty options (e.g. >5 instead of >1)\n",
    "    \n",
    "    found_config = False\n",
    "    for _ in range(100): # Try 1000 variations for this feature set\n",
    "        card_idxs = []\n",
    "        for feat in selected_features:\n",
    "            possible_idxs = feature_groups[feat]\n",
    "            card_idxs.append(random.choice(possible_idxs))\n",
    "            \n",
    "        # Check Difficulty\n",
    "        # Fast check first\n",
    "        est_diff = calculate_turns_to_win(card_idxs, truth_matrix, n_simulations=50)\n",
    "        \n",
    "        if abs(est_diff - target_difficulty) < TOLERANCE * 2:\n",
    "            # If promising, run precise check\n",
    "            precise_diff = calculate_turns_to_win(card_idxs, truth_matrix, n_simulations=50000)\n",
    "            \n",
    "            if abs(precise_diff - target_difficulty) < TOLERANCE:\n",
    "                # Accepted!\n",
    "                final_cards.append(card_idxs)\n",
    "                final_stats.append(precise_diff)\n",
    "                pbar.update(1)\n",
    "                found_config = True\n",
    "                break # Break inner loop, move to next card\n",
    "    \n",
    "    if attempts > MAX_ATTEMPTS:\n",
    "        print(\"Warning: Difficulty finding cards. Try widening tolerance or changing target.\")\n",
    "        break\n",
    "        \n",
    "pbar.close()\n",
    "print(f\"Generated {len(final_cards)} cards.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebdf583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Validate Fairness Distribution\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(sample_difficulties, bins=20, alpha=0.5, label='Random Cards (Baseline)')\n",
    "plt.hist(final_stats, bins=20, alpha=0.8, label='Selected Fair Cards')\n",
    "plt.axvline(target_difficulty, color='r', linestyle='--', label='Target')\n",
    "plt.xlabel('Average Turns to Win')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Card Difficulty (Fairness Check)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Baseline Std Dev: {np.std(sample_difficulties):.2f}\")\n",
    "print(f\"Selected Std Dev: {np.std(final_stats):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ae4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Export Final Bingo Cards\n",
    "\n",
    "cards_data = []\n",
    "for i, idxs in enumerate(final_cards):\n",
    "    card_events = events_df.iloc[idxs][\"description\"].tolist()\n",
    "    cards_data.append({\n",
    "        \"card_id\": i + 1,\n",
    "        \"events\": card_events,\n",
    "        \"avg_turns_to_win\": final_stats[i]\n",
    "    })\n",
    "    \n",
    "# Display first card as example\n",
    "print(\"Example Card 1:\")\n",
    "for e in cards_data[0][\"events\"]:\n",
    "    print(f\"- {e}\")\n",
    "    \n",
    "# Save to JSON\n",
    "import json\n",
    "out_file = PROJECT_ROOT / \"bingo_cards.json\"\n",
    "with open(out_file, \"w\") as f:\n",
    "    json.dump(cards_data, f, indent=2)\n",
    "    \n",
    "print(f\"Saved {len(cards_data)} cards to {out_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
